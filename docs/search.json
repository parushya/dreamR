[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thinking in Statistics",
    "section": "",
    "text": "Preface\n\n\n\n\n\nCliché is just an un-sexy truth. Source\n\n\n\n\nThis introductory course covers basic statistical concepts with a focus on real-world application and data analysis using R. We will learn how to collect, analyze, and interpret data, as well as present the findings. The course is designed for beginners and does not require prior programming experience.\nFollowing are needed to be installed for this course:\n\nR - Statistical Programming Language\nRStudio - Interactive Development Environment for\n\nUse the link here to install RStudio on your systems.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Course Outline",
    "section": "",
    "text": "Thinking in Statistics | With Applications in R",
    "crumbs": [
      "Course Outline"
    ]
  },
  {
    "objectID": "intro.html#thinking-in-statistics-with-applications-in-r",
    "href": "intro.html#thinking-in-statistics-with-applications-in-r",
    "title": "Course Outline",
    "section": "",
    "text": "Course Description:\nThis course explores fundamental statistical concepts with applied examples using R. It aims to provide a robust analytical framework to interpret the world quantitatively while appreciating the inherent uncertainties of empirical data.\nThe course structure would change and chapters would be added as we go along sequentially.\n\n\nCourse Objectives:\nBy the end of this course, reader will be able to:\n\nGrasp key statistical concepts and differentiate between population parameters and sample statistics.\nUse R to conduct data analysis, interpreting the results within the contexts of certainty, probability, and risk.\nCritically evaluate how statistical methods model and manage real-world uncertainties.\nCommunicate statistical findings effectively, acknowledging the limitations and assumptions underlying data interpretations.\n\n\n\nResources:\n\nThe jbstatistics youtube channel.\nWheelan, C. J. (2014). Naked statistics: Stripping the dread from the data (First published as a Norton paperback). W.W. Norton & Company.\nImai, K. (2017). Quantitative social science: An introduction. Princeton University Press.\n\n\n\nCourse Format:\nWeekly.\n\n\nSoftware Requirement:\nInstall R and RStudio on personal computers.\n\n\nWeekly Schedule:\n\nWeek 1: Introduction to Statistical Thinking\n\nDiscussion: The role of statistics in understanding truth and making decisions under uncertainty.\nLab: Introduction to R; installing R and RStudio; basic R commands.\n\n\n\nWeek 2: Populations and Samples\n\nDiscussion: Distinguishing between populations and samples; understanding parameters and statistics.\nLab: Sampling distributions and simulations in R.\n\n\n\nWeek 3: Descriptive Statistics: Telling Stories with Data\n\nDiscussion: Types of Variables - Categorical vs. Quantitative; Levels of Measurement (Nominal, Ordinal, Interval, Ratio).\nLab: Using R to organize and summarize different types of data; visualizing categorical and quantitative data distributions.\n\n\n\nWeek 4: The Concept of Probability in Statistics\n\nDiscussion: Probability as a tool for quantifying uncertainty; basic probability rules.\nLab: Probability experiments and simulations in R.\n\n\n\nWeek 5: Probability Distributions: Modeling Uncertainty\n\nDiscussion: Introduction to key probability distributions (normal, binomial).\nLab: Exploring distributions in R; applications in real-world data.\n\n\n\nWeek 6: Foundations of Inferential Statistics\n\nDiscussion: The logic and philosophy behind inferential statistics; hypothesis testing.\nLab: Performing hypothesis tests in R.\n\n\n\nWeek 7: Dummy Project with Dataset\n\nDiscussion: Review key concepts and techniques.\nLab: Use R for statistical analysis.\n\n\n\nWeek 8: Estimation: Seeking Truth Through Confidence\n\nDiscussion: Confidence intervals as expressions of precision and uncertainty.\nLab: Constructing confidence intervals in R for different parameters.\n\n\n\nWeek 9: Regression Analysis: Predicting and Explaining\n\nDiscussion: Linear regression models as tools for prediction and explanation under conditions of uncertainty.\nLab: Fitting and interpreting regression models in R.\n\n\n\nWeek 10: Testing Theories with Data\n\nDiscussion: Chi-square and ANOVA as methods for testing theoretical predictions against observed data.\nLab: Conducting and interpreting chi-square and ANOVA tests in R.\n\n\n\nWeek 11: Non-parametric Methods: When Assumptions Fail\n\nDiscussion: Introduction to non-parametric tests and their importance in statistics.\nLab: Applying non-parametric tests in R to real data.\n\n\n\nWeek 12: Causal Inference\n\nDiscussion: Potential Outcomes Framework and Directed Acyclic Graphs\nLab: TBD\n\n\n\nWeek 13: Synthesizing and Communicating Statistical Findings\n\nDiscussion: Best practices for synthesizing findings and communicating them to a non-specialist audience.\nLab: Preparing reports and presentations using R Markdown.\n\n\n\nWeek 14: TBD\n\nDiscussion and Lab: TBD.\nLab: TBD\n\n\n\nWeek 15: Next Steps\n\nDiscussion: TBD\nLab: TBD",
    "crumbs": [
      "Course Outline"
    ]
  },
  {
    "objectID": "week1-lecture.html",
    "href": "week1-lecture.html",
    "title": "Truth and Uncertainty: Role of Statistics",
    "section": "",
    "text": "This is a haywire (and hence, optional) discussion which I nevertheless would torture the listener with.\nStatistics serves as a crucial tool for knowledge creation, applicable across various fields and functions much like accounting or HR in any organization. It organizes and interprets observations—often large in number—using mathematical concepts to discern, describe, and derive insights from data. Ultimately, statistics aids in recognizing patterns in observations to explain past phenomena and, ambitiously, to predict future events.\nStatistics revolves around three meta concepts: truth, uncertainty, and chance. To illustrate, consider the question: Does drug X eliminate ailment Y in species Z?\nTo answer this, while logic based on scientific theories from the physical sciences might suggest whether Y is eliminated after administering X, empirical evidence is essential to establish the truth—determining whether X is effective against Y in Z.\nHowever, the truth in our world is not always straightforward. Suppose species Z consists of a large number of units (people, dogs, microbes, etc.). There may be characteristics in some units that make them more susceptible to Y and more likely to respond to X. This introduces two primary challenges in statistics:\nEstimation of Truth: Often, we cannot observe all units due to constraints, leading us to infer about the world through sample surveys.\nEstablishing Causality: Determining the causal relationship between variables is complex but crucial.\nBoth challenges revolve around finding an estimate of the truth in the world. Moreover, individual responses to drug X may vary, and even the same unit may show different responses over time. This variability introduces uncertainty in any estimate of truth, encompassing concepts like variance, variability, and heterogeneity.\n\n\n\n\n\n\nAlternatively, you can watch the following videos",
    "crumbs": [
      "Introduction to Statistical Thinking",
      "Truth and Uncertainty: Role of Statistics"
    ]
  },
  {
    "objectID": "week1-lab.html",
    "href": "week1-lab.html",
    "title": "Intro to R",
    "section": "",
    "text": "R and RStudio\nR is a free open-source statistical programming language. We generally use R through RStudio which is an integrated development environment (IDE). Essentially, it is the graphic user interface that allows us to use R efficiently. It has point-and-click functionality also (which we would not use a lot).\nRStudio Screen\nR Scripts: This is where put your code in a script. The script is saved with a .R extension. An R script is a text file that you can read on text editors too. We use RStudio to run the code in a way that the computer understands.\nConsole: Output from your code appears here. You can also write the code directly here. But it does not get saved. Also, by default, it shows only a limited number of previous steps (commands + outputs). Not a good practice to code here.\nEnvironment: All the objects, datasets, lists, etc that you have created/loaded in the environment appear here. Alongside, you also see the custom functions that you might create.\nFile Browser/Help/Plot: Internal file navigator and help documentation for packages and functions appear here. Further, when you plot anything, that also gets shown here.\nComments: R interprets every line in the script as a separate command. And it does for each line unless preceded by a #. Comments signal to R that what follows the # is to be ignored.We use comments to write explanatory notes about the code. A comment should explain the purpose of a command or code and not just be a description of what it does.",
    "crumbs": [
      "Introduction to Statistical Thinking",
      "Intro to `R`"
    ]
  },
  {
    "objectID": "week1-lab.html#basics",
    "href": "week1-lab.html#basics",
    "title": "Intro to R",
    "section": "Basics",
    "text": "Basics\nR uses &lt;- as the assignment operator. To the left of it is an object (sort of like a box that stores values which are to the right of the operator).\nSyntax: object &lt;- value/data\n\nExercise 1Code 1\n\n\n\nCreate a new .R script. Name it and save it on your system.\n\nR does all the functions of a calculator. Write some code in the script that\n\n\nAdds two numbers\nMultiplies three numbers\nPrints your name\n\n\nRun each command separately by using cmd + Enter / ctrl + Enter.\nAssign the outputs from 2 to different objects.\nPrint the objects with some description using paste().\nRun the whole file.\n\n\n\nYou can start a new script through many different ways:\n\nctrl + shift + n\nClick on the tiny white page button with a green+sign on the upper left corner of the screen\nClick on File &gt; New file&gt; R script\n\nSaving a script:\n\nCtrl + S\nEnter the name of the script, and add .R as a suffix. For example: xyzbasic.R\n\n\n#2. \n2 + 7\n\n56 * 9 * 33\n\nprint(\"Parushya\")\n\nThe output is displayed in the console.\n\n#4\n\n\nsum_2 &lt;- 2 + 7\n\nprod_3 &lt;- 56 * 9 * 33\n\nname &lt;- \"parushya\"\n\n\n#5\n\npaste(\"Sum of 2 and 7 is\", sum_2)\n\npaste(\"Product of 56, 9 and 33 is\", prod_3)\n\npaste(\"This very fancy R code was written by\", name)",
    "crumbs": [
      "Introduction to Statistical Thinking",
      "Intro to `R`"
    ]
  },
  {
    "objectID": "week1-lab.html#objects-datatypes-and-data-structures",
    "href": "week1-lab.html#objects-datatypes-and-data-structures",
    "title": "Intro to R",
    "section": "Objects, Datatypes, and Data Structures",
    "text": "Objects, Datatypes, and Data Structures\n\n\n\n\n\n\nExercise 2\n\n\n\nRun the following code in the same script that we created\n\nclass(sum_2)\n\nclass(prod_3)\n\nclass(name)\n\n\n\nEverything in R is called an “object”\n“Objects” contain “data”.\nThe three variables we created - sum_2, prod_3, and name - were all basic objects.\nR has 5 basic or “atomic” classes/datatypes of objects.\n\nCharacter - (abc)\nNumeric - (real numbers) - (1,7.5,etc)\nInteger - (1,2,0,-896)\nLogical - (True/False)\nComplex - (1, 0+i)\n\nData structures are bigger containers that hold many objects.\nTwo basic or “atomic” data structures in R are:\n\nVectors: can hold objects of same datatype\nLists: can hold objects with different datatypes\n\n\n\n\n\n\n\nUnderstanding Vectors\n\n\n\nWe can create a vector using the “c()” command.\n\na_num &lt;- c(0,0.7,9,2,3,4,-1)            # numeric or double\n\nb_logical &lt;- c(TRUE,FALSE,TRUE,TRUE,TRUE) # logical\n\nc_logical &lt;- c(T,F,T,T,T) # also logical - Never use T and F as it leads to errors in analysis\n\nd_char &lt;- c(\"Sheila\", \"Nila\", \"Camilla\")  # character\n\ne_int &lt;- 1:20 # integer\n\nf_int &lt;- c(1,2,3,4,5)  # integer\n\ng_int &lt;- c(1+0i,2+4i) # complex numbers\n\nBasic vectors are uni-dimensional. We can make a two dimensional vector, which is called matrix.\n\nWorking with matrices\n\n# Creating Blank Matrix\nm_1 &lt;- matrix(nrow=3,ncol=4)\nm_1      \n\n     [,1] [,2] [,3] [,4]\n[1,]   NA   NA   NA   NA\n[2,]   NA   NA   NA   NA\n[3,]   NA   NA   NA   NA\n\ndim(m_1)\n\n[1] 3 4\n\n\n\n?matrix # Help documentation\n\n# Creating Matrix with elements\n\nm_2 &lt;- matrix(1:10, nrow = 3, ncol = 4) # Why the warning?\nm_2\n\n# With correct number of elements\nm_3 &lt;- matrix(1:18, nrow=9, ncol=2))\nm3\n\nLogic of matrices\nMatrices are constructed column-wise. So, it fills the upper left corner, and then runs down along.\nIndexing in matrices\n\n# Rows & Columns ----    \n# Very simply the syntax is:  (2,3) = (Rows, Columns)\n# m[1,] - 1st row\n# m[2,] - 2nd row\n# m[,3] - 3rd column  \n# m[,5] - 5th column\n# m[,7] - 7th column\n\n\n# What if you already have a vector?\n# Example: You have received a list of students who have skipped school today.\n# You know which section they are in, and want to create a matrix.\nk &lt;- c(\"Hashem\", \"John\", \"Cecillia\", \"Minha\", \"Parushya\", \"Keeheon\")\nk\n\n[1] \"Hashem\"   \"John\"     \"Cecillia\" \"Minha\"    \"Parushya\" \"Keeheon\" \n\ndim(k) &lt;- c(3,2)\nk\n\n     [,1]       [,2]      \n[1,] \"Hashem\"   \"Minha\"   \n[2,] \"John\"     \"Parushya\"\n[3,] \"Cecillia\" \"Keeheon\" \n\ncolnames(k) &lt;- c(\"Section A\", \"Section B\")\n\nk\n\n     Section A  Section B \n[1,] \"Hashem\"   \"Minha\"   \n[2,] \"John\"     \"Parushya\"\n[3,] \"Cecillia\" \"Keeheon\" \n\nrownames(k) &lt;- c(\"Student 1\", \"Student 2\", \"Student 3\")\n\nk\n\n          Section A  Section B \nStudent 1 \"Hashem\"   \"Minha\"   \nStudent 2 \"John\"     \"Parushya\"\nStudent 3 \"Cecillia\" \"Keeheon\" \n\n\nBinding vectors together to make a matrix\n\n# Binding\nx &lt;- 1:3\ny &lt;- 4:6\nz &lt;- c(\"Camilla\",\"Nila\",\"Duflo\",\"Akbar\")\n\nx\n\n[1] 1 2 3\n\ny\n\n[1] 4 5 6\n\nz\n\n[1] \"Camilla\" \"Nila\"    \"Duflo\"   \"Akbar\"  \n\nrbind(x,y) # Stitches vector row wise, or appends it horizontally\n\n  [,1] [,2] [,3]\nx    1    2    3\ny    4    5    6\n\ncbind(x,y) # Stitches vector column wise, or vertically\n\n     x y\n[1,] 1 4\n[2,] 2 5\n[3,] 3 6\n\n\n\n\n\n\nLists\nIf we want to create something that stores objects of different classes together, we use another data structure called list.\nA list can contain two or more classes of objects with different lengths.\n\n\n\n\n\n\nCreating lists\n\nlist_1 &lt;- list(\"a\" = 2.5, \"b\" = TRUE, \"c\" = 1:3)\n\nlist_1\n\n$a\n[1] 2.5\n\n$b\n[1] TRUE\n\n$c\n[1] 1 2 3\n\n\nWe created a list with objects of three different types - numeric, logical, and integer vector.\n\n# Structure of the list\nstr(list_1)\n\nList of 3\n $ a: num 2.5\n $ b: logi TRUE\n $ c: int [1:3] 1 2 3\n\n\nWe can also create a list with existing vectors.\n\n# A new vector\nname_vec &lt;- c(\"Camilla\",\"Nila\",\"Duflo\",\"Akbar\")\n\n# And then lets use the vectors we already have in the environment\nlist_2 &lt;- list(name_vec, c_logical, d_char, f_int, e_int, a_num)\nlist_2\n\n[[1]]\n[1] \"Camilla\" \"Nila\"    \"Duflo\"   \"Akbar\"  \n\n[[2]]\n[1]  TRUE FALSE  TRUE  TRUE  TRUE\n\n[[3]]\n[1] \"Sheila\"  \"Nila\"    \"Camilla\"\n\n[[4]]\n[1] 1 2 3 4 5\n\n[[5]]\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n[[6]]\n[1]  0.0  0.7  9.0  2.0  3.0  4.0 -1.0\n\n\n\n# let's check the classes of objects\nclass(list_2[[2]])\nclass(list_2[[3]])\n\n# And their lengths\nlength(list_2[[2]])\nlength(list_2[[3]])\n\nAccessing elements in a List\nBy indices in a list\n\n# So lists are printed differently, and elements of a list will have [[]] i.e 2 brackets.    \n\nlist_2\n\n[[1]]\n[1] \"Camilla\" \"Nila\"    \"Duflo\"   \"Akbar\"  \n\n[[2]]\n[1]  TRUE FALSE  TRUE  TRUE  TRUE\n\n[[3]]\n[1] \"Sheila\"  \"Nila\"    \"Camilla\"\n\n[[4]]\n[1] 1 2 3 4 5\n\n[[5]]\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n[[6]]\n[1]  0.0  0.7  9.0  2.0  3.0  4.0 -1.0\n\n\n\n## Accessing elements | run each of the follwing lines and see the output\nlist_2[[2]] \nlist_2[2]\nlist_2[1][2]\nlist_2[[1]][1]\nlist_2[[1]][[1]]\nlist_2[[1]][2]\n\nBy using names or tags\n\nlist_3 &lt;- list(name = \"John\", age = 19, speaks = c(\"English\", \"French\"))\n\n# access elements by name\nlist_3$name\nlist_3$age\nlist_3$speaks\n\n# access elements by integer index\nlist_3[c(1, 2)]\nlist_3[-2]\n\n# access elements by logical index\nlist_3[c(TRUE, FALSE, FALSE)]\n\n# access elements by character index\nlist_3[c(\"age\", \"speaks\")]\n\nModifying lists\nAdding components in a list\n\nlist_4 &lt;- list(name = \"Clair\", age = 19, speaks = c(\"English\", \"French\"))\n\n# assign a new element to the list using double brackets [[]]\nlist_4[[\"married\"]] &lt;- FALSE\n\n# print the updated list\nlist_4\n\n$name\n[1] \"Clair\"\n\n$age\n[1] 19\n\n$speaks\n[1] \"English\" \"French\" \n\n$married\n[1] FALSE\n\n\nDeleting components in a list\n\nlist_5 &lt;- list(name = \"Clair\", age = 19, speaks = c(\"English\", \"French\"))\n\n# remove an element from the list using double brackets [[]]\nlist_5[[\"age\"]] &lt;- NULL\n\n# print the structure of the updated list\nstr(list_5)\n\nList of 2\n $ name  : chr \"Clair\"\n $ speaks: chr [1:2] \"English\" \"French\"\n\n# remove an element from the list using $ notation\nlist_5$married &lt;- NULL\n\n# print the structure of the updated list\nstr(list_5)\n\nList of 2\n $ name  : chr \"Clair\"\n $ speaks: chr [1:2] \"English\" \"French\"",
    "crumbs": [
      "Introduction to Statistical Thinking",
      "Intro to `R`"
    ]
  },
  {
    "objectID": "week1-lab.html#factors",
    "href": "week1-lab.html#factors",
    "title": "Intro to R",
    "section": "Factors",
    "text": "Factors\nFactors are used for categorical data - both nominal and ordinal ones.\nFactors are treated as a separate datatype in R. Technically, factors are stored as a vector of integer values corresponding to the character type objects which they are used to represent.\n\n\n\n\n\n\nYou can define a factor by using factor() command.\n\nvec_1 &lt;- c(\"yes\", \"no\", \"yes\")\n\nfct_1 &lt;- factor(c(\"yes\", \"no\", \"yes\"))\n\n# Notice the difference in outputs\n\nvec_1\n\n[1] \"yes\" \"no\"  \"yes\"\n\nfct_1\n\n[1] yes no  yes\nLevels: no yes\n\n\n\n# Btw, table() command cn be used in R for cross-tabulations\n# with both vector and factor datatypes. \n\ntable(vec_1)\n\nvec_1\n no yes \n  1   2 \n\ntable(fct_1)\n\nfct_1\n no yes \n  1   2 \n\n\nOrdering Factors\nSometimes it is essential to specify the orders of your factor levels. Particularly during modelling and estimation with binary or categorical variables, given that the first level of factor is used in most functions, like lm(linear regression command in R), will be treated as baseline level or category.\nFor example, we have a variable measuring dose of vaccine administered (placebo, medium, high). Here specifying order becomes important as all measurements of the treatment efficacy will have to be with respect to the baseline category.\nWe use levels() within factor() command to do this.\n\nfct_2 &lt;- factor(c(\"High\", \"High\", \"Medium\", \"Medium\", \"High\", \"High\",\"Placebo\"))\nfct_2   \n\n[1] High    High    Medium  Medium  High    High    Placebo\nLevels: High Medium Placebo\n\n# (Order is often determined using alphabetical variables by default) (H-M-P)\n\n# Ordering it\nfct_2 &lt;- factor(c(\"Placebo\", \"High\", \"Medium\", \"Placebo\", \"Medium\", \n            \"Medium\", \"High\", \"High\"),\nlevels = c(\"Placebo\",\"Medium\",\"High\"))\n\nfct_2\n\n[1] Placebo High    Medium  Placebo Medium  Medium  High    High   \nLevels: Placebo Medium High",
    "crumbs": [
      "Introduction to Statistical Thinking",
      "Intro to `R`"
    ]
  },
  {
    "objectID": "week1-lab.html#dataframes",
    "href": "week1-lab.html#dataframes",
    "title": "Intro to R",
    "section": "Dataframes",
    "text": "Dataframes\nIn R, dataframes are data structure which store data in a tabular format.\n\n\n\n\n\n\nWe create dataframes using data.frame() command.\n\ndf_1 &lt;- data.frame(\n    Foo= 15:18, \n    Bar= c(T, F, T, T), \n    Name= c(\"Penny\", \"Sheldon\", \"Rajesh\", \"Leonard\")\n)\n\nExploring the contents and structure of the dataframe\n\n# Viewing dataframe\ndf_1 # In Console\nView(df_1)  # In Viewer\n\n# structure of dataframe\nstr(df_1)\n\n# Names of columns/variables\nnames(df_1)\n\n# Dimesnions of Dataframe\nnrow(df_1)      \nncol(df_1)\ndim(df_1)\n\n# Summary of dataframe\nsummary(df_1) # See the output closely | very useful for understanding the dataset\n\nAccessing the objects inside dataframe\n\n# Access Items using [] \ndf_1[1]\n\n  Foo\n1  15\n2  16\n3  17\n4  18\n\n# Access Items using [[]]\ndf_1[['Bar']]\n\n[1]  TRUE FALSE  TRUE  TRUE\n\n# Access Items using $\ndf_1$Bar\n\n[1]  TRUE FALSE  TRUE  TRUE\n\n# Access particular data point\ndf_1$Foo[3]\n\n[1] 17\n\n# what will be the output?\ndf_1[1,3]\n\n[1] \"Penny\"\n\n\nTidyverse package has a very efficient framwork for working with dataset. Check the tidyverse book from day 2 for the same.",
    "crumbs": [
      "Introduction to Statistical Thinking",
      "Intro to `R`"
    ]
  },
  {
    "objectID": "week2-lecture.html",
    "href": "week2-lecture.html",
    "title": "Population and Sample",
    "section": "",
    "text": "Let’s revisit our initial question: Does drug X treat ailment Y in species Z?\nThe first step in answering this question is to define the population of interest. In this case, the population includes all members of species Z who have ailment Y.\n\n\n\n\n\n\nDefining Population and Sample\n\n\n\n\nPopulation: The entire group we want to study or draw conclusions about.\nSample: A subset of the population that is selected for study.\n\n\n\nIn many cases, studying an entire population is impractical due to its large size or inaccessibility. Instead, researchers work with a sample, a smaller group carefully chosen to represent the broader population.\n\nWhat Makes a Sample Representative?\nA representative sample is a subset of the population that accurately reflects its characteristics. For a sample to be considered representative, every member of the population should have a non-zero probability of being selected. Ideally, in random sampling, each member has an equal chance of selection, reducing bias.\nA whole field of sampling theory explores different ways to select samples, including:\n\nSimple Random Sampling – Every individual has an equal chance of selection.\nStratified Sampling – The population is divided into subgroups, and random samples are taken from each.\nCluster Sampling – The population is divided into clusters, and entire clusters are randomly selected.\nSystematic Sampling – Every nth individual is chosen from a list.\n\n\n\nStatistical Inference: Learning About the Population from a Sample\nSince studying an entire population is often impossible, we rely on statistical inference, which is the process of drawing conclusions about a population based on data from a sample.\nThere are two main types of statistical inference:\n\nEstimation – Using sample statistics (e.g., sample mean) to estimate population parameters (e.g., population mean). Examples include:\n\nPoint estimation (e.g., using the sample mean as an estimate of the population mean).\nConfidence intervals, which provide a range of plausible values for the population parameter.\n\nHypothesis Testing – Using sample data to test assumptions about the population. For example:\n\nTesting whether drug X significantly improves health outcomes in species Z.\nDetermining whether two groups have different average responses to a treatment.\n\n\n\n\nPopulation Parameters vs. Sample Statistics\nThe goal of using a sample is to infer information about the population. The characteristics we study can be numerical (e.g., average age) or categorical (e.g., proportion of individuals responding to a drug).\n\nParameter: A fixed but often unobservable value that describes a characteristic of the entire population (e.g., the true average age of species Z worldwide).\nStatistic: A value computed from the sample that estimates the corresponding population parameter (e.g., the average age in a sample of species Z).\n\n\nKey Relationships\n\nPopulation → Parameter (e.g., true average lifespan)\nSample → Statistic (e.g., sample mean lifespan)\n\nA well-chosen representative sample ensures that sample statistics closely approximate population parameters. However, due to sampling variability, the sample statistic will never be exactly equal to the population parameter. Statistical inference methods, such as confidence intervals and hypothesis testing, help quantify uncertainty and determine how well our sample estimates generalize to the population.\nBy selecting a robust sample and applying appropriate statistical techniques, we can make valid and reliable inferences about the population.",
    "crumbs": [
      "Populations and Samples",
      "Population and Sample"
    ]
  },
  {
    "objectID": "week2-lab.html",
    "href": "week2-lab.html",
    "title": "Getting Data in R",
    "section": "",
    "text": "Packages\nPackages in R are containers for functions. A lot of packages are already installed when you install R.\n# Check available packages\nlibrary()\nYou can install packages from Comprehensive R Archive Network or CRAN which is an online storage of peer-reviewed and documented packages.\nThe command for loading a package is install.package().\n# installing package. Eg, tidyverse\n\ninstall.packages(\"tidyverse\") # You have ti run this once on system\n\nlibrary(tidyverse) # Once installed library(&lt;packagename&gt;) command loads all the functions associated with the package in the current session for use",
    "crumbs": [
      "Populations and Samples",
      "Getting Data in R"
    ]
  },
  {
    "objectID": "week2-lab.html#packages",
    "href": "week2-lab.html#packages",
    "title": "Getting Data in R",
    "section": "",
    "text": "Exercise 1\n\n\n\nLoad the following four packages/libraries, which we would be using later - janitor, here, readstata13, and tinytex.\n\ninstall.packages(\"&lt;package name&gt;\")\nlibrary(&lt;package name&gt;)",
    "crumbs": [
      "Populations and Samples",
      "Getting Data in R"
    ]
  },
  {
    "objectID": "week2-lab.html#importing-and-exporting-datasets",
    "href": "week2-lab.html#importing-and-exporting-datasets",
    "title": "Getting Data in R",
    "section": "Importing and Exporting Datasets",
    "text": "Importing and Exporting Datasets\n\n\n\n\n\nRStudio Screen\n\n\n\n\nR has a range of functions for using different types of data. But before loading datasets let’s understand the concept of working directories.\nA working directory is sort of the “office” that you operate from. They tell R where to operate from.\nWorking directories are specified using a file path i.e. the address in your computer where your script will be stored, or where your dataset is kept.\n\n# Commands:\ngetwd() # Gets the present directory or pathway where you are operating from\n     \nsetwd(\"&lt;press tab here&gt;\") # Setting new directory as working directory\n\nlist.files()  #list the files in the working directory\n\nBelow is a limited list of commands for loading/importing most commonly used dataset types.\n\nread.csv(\"FileName\") # reads CSV files / press tab inside the quotes\nread_csv(\"Pathname/filename.csv\")  \n\n# The part before :: in the following code refers to the package from where the \n#  function comes from. You will need to load those packages first.\n\nreadxl::read_excel() # read excel files\nreadxl::read_xlsx() # reads excel workbooks\nhaven::read_dta()   # reads stata dta files\n\n# example: \n    \ndataframe1 &lt;- read.csv(\"&lt;file path&gt;\")\n\n\nExercise 2Code 2\n\n\n\nDownload the folder Datasets-mathcamp from the link\nLoad datasets using the functions referred above\nExplore the contents of datasets using the functions we learned in the previous section.\nSave these datasets with a different names at a different location.\n\n\n\n\nDownload the folder Datasets-mathcamp from the link\nLoad datasets using the functions referred above.\n\nANES dataset | American National Election Study (2016tim?)\n\nanes_df &lt;- read.csv(\"Datasets-mathcamp/anes_specialstudy_2020-2022_socialmedia_csv_20230705/anes_specialstudy_2020-2022_socialmedia_csv_20230705.csv\") # base R\n\nanes_df_2 &lt;- read_csv(\"Datasets-mathcamp/anes_specialstudy_2020-2022_socialmedia_csv_20230705/anes_specialstudy_2020-2022_socialmedia_csv_20230705.csv\")  # tidyverse\n\nWorld Political Cleavages and Inequality Database\n\nwid_df &lt;- readxl::read_excel(\"Datasets-mathcamp/World Inequality Database/gmp-macro-final-party.xlsx\")\n\nDatabase on Political Institutions\n\ndpi20_df &lt;- read_dta(\"Datasets-mathcamp/DPI/DPI2020_stata13.dta\") # Why error?\ndpi20_df_2 &lt;- read.dta13(\"Datasets-mathcamp/DPI/DPI2020_stata13.dta\")\n\nVDem dataset | Varieties of democracy\n\nvdem_df &lt;- readRDS(\"Datasets-mathcamp/V-Dem-CY-Full+Others-v12.rds\")\n\n# RDS and Rdata are native R file storage formats\n\n\nExplore the contents of datasets using the functions we learned in the previous section.\n\n\n#Hint: summary, str\n\n\nSave these datsets with a different name at a different location.\n\n\n# Hint\n# write.csv() and equivalents\n\n# saveRDS and save for native R data struture types",
    "crumbs": [
      "Populations and Samples",
      "Getting Data in R"
    ]
  }
]